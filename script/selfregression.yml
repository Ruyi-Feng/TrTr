task: pretrain
is_train: true
architecture: selfregression
train_epochs: 10
batch_size: 4
input_len: 60
pred_len: 60
d_model: 128
nhead: 8
e_layers: 6
d_layers: 6
dropout: 0.1
learning_rate: 0.0001
warmup_steps: 800
pos_emb: 'nrml'
