task: pretrain
is_train: true
architecture: mae
train_epochs: 10
batch_size: 4
input_len: 10
pred_len: 10
d_model: 128
nhead: 8
e_layers: 6
d_layers: 6
dropout: 0.1
learning_rate: 0.0001
warmup_steps: 800
pos_emb: 'nrml'
data_form: 'stack'
frm_embed: 60
id_embed: 100