task: pretrain
is_train: true
architecture: histlabel
batch_size: 1024
input_len: 30
pred_len: 10
d_model: 256
nhead: 8
e_layers: 3
d_layers: 3
dropout: 0.1
learning_rate: 0.01
warmup_steps: 200
pos_emb: 'nrml'